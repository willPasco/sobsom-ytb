import os
import uuid
import subprocess
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
import whisper
import torch
import yt_dlp

# â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

UPLOAD_DIR = Path("temp/uploads")
OUTPUT_DIR = Path("temp/outputs")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

VALID_MODELS  = {"tiny", "medium", "large"}
VALID_DEVICES = {"cpu", "cuda"}

HAS_CUDA = torch.cuda.is_available()

app = FastAPI(title="Video Clipper")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory="../frontend"), name="static")

# Cache de modelos jÃ¡ carregados para nÃ£o recarregar desnecessariamente
model_cache: dict = {}

def get_model(model_name: str, device: str):
    key = f"{model_name}_{device}"
    if key not in model_cache:
        print(f"â³ Carregando modelo '{model_name}' no dispositivo '{device}'...")
        model_cache[key] = whisper.load_model(model_name, device=device)
        print(f"âœ… Modelo '{model_name}' carregado em {device.upper()}!")
    return model_cache[key]

# â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def download_youtube(url: str, session_id: str) -> tuple[Path, str]:
    output_template = str(UPLOAD_DIR / f"{session_id}.%(ext)s")
    ydl_opts = {
        "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
        "outtmpl": output_template,
        "quiet": True,
        "no_warnings": True,
        "merge_output_format": "mp4",
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)
        title = info.get("title", "video")

    video_path = UPLOAD_DIR / f"{session_id}.mp4"
    if not video_path.exists():
        candidates = list(UPLOAD_DIR.glob(f"{session_id}.*"))
        if not candidates:
            raise HTTPException(status_code=500, detail="Falha ao baixar o vÃ­deo do YouTube.")
        video_path = candidates[0]

    return video_path, title


def process_video_file(video_path: Path, keyword: str, padding: int, session_id: str, model_name: str, device: str):
    output_dir = OUTPUT_DIR / session_id
    output_dir.mkdir(parents=True, exist_ok=True)

    model = get_model(model_name, device)

    print(f"ğŸ™ï¸ Transcrevendo {video_path.name} [{model_name} / {device}]...")
    result = model.transcribe(str(video_path), language="pt", word_timestamps=True)

    keyword_lower = keyword.lower()
    matches = []

    for segment in result["segments"]:
        if keyword_lower in segment["text"].lower():
            start = max(0, segment["start"] - padding)
            end = segment["end"] + padding
            matches.append({
                "start": start,
                "end": end,
                "text": segment["text"].strip(),
            })

    if not matches:
        raise HTTPException(
            status_code=404,
            detail=f"Nenhuma ocorrÃªncia de '{keyword}' encontrada no vÃ­deo."
        )

    clips = []
    for i, match in enumerate(matches):
        clip_name = f"clipe_{i+1:02d}.mp4"
        clip_path = output_dir / clip_name

        subprocess.run([
            "ffmpeg", "-y",
            "-i", str(video_path),
            "-ss", str(match["start"]),
            "-to", str(match["end"]),
            "-c:v", "libx264",
            "-c:a", "aac",
            "-loglevel", "error",
            str(clip_path)
        ], check=True)

        clips.append({
            "name": clip_name,
            "text": match["text"],
            "start": round(match["start"], 1),
            "end": round(match["end"], 1),
            "download_url": f"/download/{session_id}/{clip_name}",
        })

    print(f"âœ… {len(clips)} clipes gerados para sessÃ£o {session_id}")
    return clips

# â”€â”€â”€ Endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/")
def index():
    return FileResponse("../frontend/index.html")

@app.get("/capabilities")
def capabilities():
    """Informa ao frontend se CUDA estÃ¡ disponÃ­vel."""
    return {"cuda_available": HAS_CUDA}

@app.post("/process/upload")
async def process_upload(
    video: UploadFile = File(...),
    keyword: str = Form(...),
    padding: int = Form(3),
    model_name: str = Form("medium"),
    device: str = Form("cpu"),
):
    if model_name not in VALID_MODELS:
        raise HTTPException(status_code=400, detail=f"Modelo invÃ¡lido: {model_name}")
    if device not in VALID_DEVICES:
        raise HTTPException(status_code=400, detail=f"Dispositivo invÃ¡lido: {device}")
    if device == "cuda" and not HAS_CUDA:
        raise HTTPException(status_code=400, detail="GPU NVIDIA nÃ£o disponÃ­vel nesta mÃ¡quina.")

    session_id = str(uuid.uuid4())[:8]
    video_path = UPLOAD_DIR / f"{session_id}_{video.filename}"

    with open(video_path, "wb") as f:
        f.write(await video.read())

    try:
        clips = process_video_file(video_path, keyword, padding, session_id, model_name, device)
        return {"session_id": session_id, "keyword": keyword, "total_clips": len(clips), "clips": clips}
    finally:
        video_path.unlink(missing_ok=True)


@app.post("/process/youtube")
async def process_youtube(
    url: str = Form(...),
    keyword: str = Form(...),
    padding: int = Form(3),
    model_name: str = Form("medium"),
    device: str = Form("cpu"),
):
    if model_name not in VALID_MODELS:
        raise HTTPException(status_code=400, detail=f"Modelo invÃ¡lido: {model_name}")
    if device not in VALID_DEVICES:
        raise HTTPException(status_code=400, detail=f"Dispositivo invÃ¡lido: {device}")
    if device == "cuda" and not HAS_CUDA:
        raise HTTPException(status_code=400, detail="GPU NVIDIA nÃ£o disponÃ­vel nesta mÃ¡quina.")

    session_id = str(uuid.uuid4())[:8]
    video_path = None

    try:
        print(f"â¬‡ï¸  Baixando: {url}")
        video_path, title = download_youtube(url, session_id)
        print(f"âœ… Download concluÃ­do: {title}")

        clips = process_video_file(video_path, keyword, padding, session_id, model_name, device)
        return {
            "session_id": session_id,
            "keyword": keyword,
            "title": title,
            "total_clips": len(clips),
            "clips": clips,
        }
    finally:
        if video_path and video_path.exists():
            video_path.unlink(missing_ok=True)


@app.get("/download/{session_id}/{filename}")
def download_clip(session_id: str, filename: str):
    clip_path = OUTPUT_DIR / session_id / filename
    if not clip_path.exists():
        raise HTTPException(status_code=404, detail="Clipe nÃ£o encontrado.")
    return FileResponse(path=clip_path, media_type="video/mp4", filename=filename)


@app.delete("/session/{session_id}")
def cleanup_session(session_id: str):
    import shutil
    session_dir = OUTPUT_DIR / session_id
    if session_dir.exists():
        shutil.rmtree(session_dir)
    return {"status": "ok"}